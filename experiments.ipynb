{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torch.nn import BatchNorm2d, Softmax2d\n",
    "from torchvision.models.resnet import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = torch.randn(10, 50), torch.randn(20, 50)\n",
    "torch.nn.functional.softmax(torch.cdist(a, b, p=2), dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3072, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Conv2d(1024 + 2048, 10, 1, bias=False).weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualLandmarkNet(torch.nn.Module):\n",
    "    def __init__(self, init_model: ResNet, num_landmarks: int = 8,\n",
    "                 num_classes: int = 2000, landmark_dropout: float = 0.3) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        init_model: ResNet\n",
    "            The pretrained ResNet model\n",
    "        num_landmarks: int\n",
    "            Number of landmarks to detect\n",
    "        num_classes: int\n",
    "            Number of classes for the classification\n",
    "        landmark_dropout: float\n",
    "            Probability of dropping out a given landmark\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # The base model\n",
    "        self.num_landmarks = num_landmarks\n",
    "        self.conv1 = init_model.conv1\n",
    "        self.bn1 = init_model.bn1\n",
    "        self.relu = init_model.relu\n",
    "        self.maxpool = init_model.maxpool\n",
    "        self.layer1 = init_model.layer1\n",
    "        self.layer2 = init_model.layer2\n",
    "        self.layer3 = init_model.layer3\n",
    "        self.layer4 = init_model.layer4\n",
    "        self.finalpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # New part of the model\n",
    "        self.softmax: Softmax2d = torch.nn.Softmax2d()\n",
    "        self.batchnorm = BatchNorm2d(11)\n",
    "        self.fc_landmarks = torch.nn.Conv2d(1024 + 2048, num_landmarks + 1, 1, bias=False)\n",
    "        self.fc_class_landmarks = torch.nn.Linear(1024 + 2048, num_classes, bias=False)\n",
    "        self.modulation = torch.nn.Parameter(torch.ones((1,1024 + 2048,num_landmarks + 1)))\n",
    "        self.dropout = torch.nn.Dropout(landmark_dropout)\n",
    "        self.dropout_full_landmarks = torch.nn.Dropout1d(landmark_dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            Input image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        all_features: torch.Tensor\n",
    "            Features per landmark\n",
    "        maps: torch.Tensor\n",
    "            Attention maps per landmark\n",
    "        scores: torch.Tensor\n",
    "            Classification scores per landmark\n",
    "        \"\"\"\n",
    "        # Pretrained ResNet part of the model\n",
    "        x = self.conv1(x) # shape: [b, 64, h1, w1], e.g. h1=w1=112\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x) # shape: [b, 64, h2, w2], e.g. h2=w2=56\n",
    "        x = self.layer1(x) # shape: [b, 256, h2, w2], e.g. h2=w2=56\n",
    "        x = self.layer2(x) # shape: [b, 512, h3, w3], e.g. h2=w2=28\n",
    "        l3 = self.layer3(x) # shape: [b, 1024, h3, w3], e.g. h2=w2=28\n",
    "        x = self.layer4(l3) # shape: [b, 2048, h4, w4], e.g. h2=w2=7\n",
    "        # x = torch.nn.functional.upsample_bilinear(x, size=(l3.shape[-2], l3.shape[-1]))\n",
    "        x = torch.nn.functional.interpolate(x, size=(l3.shape[-2], l3.shape[-1]), mode='bilinear') # shape: [b, 2048, h, w], e.g. h=w=14\n",
    "        x = torch.cat((x, l3), dim=1) # shape: [b, 2048 + 1024, h, w], e.g. h=w=14\n",
    "\n",
    "        # Compute per landmark attention maps\n",
    "        # (b - a)^2 = b^2 - 2ab + a^2, b = feature maps resnet, a = convolution kernel\n",
    "        batch_size = x.shape[0]\n",
    "        ab = self.fc_landmarks(x) # shape: [b, nlandmark + 1, h, w]\n",
    "        print('ab shape:', ab.shape)\n",
    "        b_sq = x.pow(2).sum(1, keepdim=True) # shape: [b, 1, h, w]\n",
    "        print('b_sq shape:', b_sq.shape)\n",
    "        b_sq = b_sq.expand(-1, self.num_landmarks + 1, -1, -1) # shape: [b, nlandmark + 1, h, w]\n",
    "        print('b_sq shape:', b_sq.shape)\n",
    "        print('fc_landmarks.weight shape:', self.fc_landmarks.weight.shape)\n",
    "        a_sq = self.fc_landmarks.weight.pow(2).sum(1).unsqueeze(1).expand(-1, batch_size, x.shape[-2], x.shape[-1])\n",
    "        print('a_sq shape:', a_sq.shape)\n",
    "        a_sq = a_sq.permute(1, 0, 2, 3)\n",
    "        maps = b_sq - 2 * ab + a_sq\n",
    "        maps = -maps\n",
    "\n",
    "        # Softmax so that the attention maps for each pixel add up to 1\n",
    "        print('maps shape:', maps.shape)\n",
    "        maps = self.softmax(maps)\n",
    "\n",
    "        # Use maps to get weighted average features per landmark\n",
    "        feature_tensor = x\n",
    "        all_features = ((maps).unsqueeze(1) * feature_tensor.unsqueeze(2)).mean(-1).mean(-1)\n",
    "        print('all_features shape:', all_features.shape)\n",
    "\n",
    "        # Classification based on the landmarks\n",
    "        all_features_modulated = all_features * self.modulation\n",
    "        all_features_modulated = self.dropout_full_landmarks(all_features_modulated.permute(0,2,1)).permute(0,2,1)\n",
    "        scores = self.fc_class_landmarks(all_features_modulated.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        return all_features, maps, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet50()\n",
    "landmark_net = IndividualLandmarkNet(init_model=resnet)\n",
    "x = torch.randn(3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab shape: torch.Size([1, 9, 14, 14])\n",
      "b_sq shape: torch.Size([1, 1, 14, 14])\n",
      "b_sq shape: torch.Size([1, 9, 14, 14])\n",
      "fc_landmarks.weight shape: torch.Size([9, 3072, 1, 1])\n",
      "a_sq shape: torch.Size([9, 1, 14, 14])\n",
      "maps shape: torch.Size([1, 9, 14, 14])\n",
      "all_features shape: torch.Size([1, 3072, 9])\n"
     ]
    }
   ],
   "source": [
    "feats, maps, scores = landmark_net(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualLandmarkNetModified(torch.nn.Module):\n",
    "    def __init__(self, init_model: ResNet, num_landmarks: int = 8,\n",
    "                 num_classes: int = 2000, landmark_dropout: float = 0.3) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        init_model: ResNet\n",
    "            The pretrained ResNet model\n",
    "        num_landmarks: int\n",
    "            Number of landmarks to detect\n",
    "        num_classes: int\n",
    "            Number of classes for the classification\n",
    "        landmark_dropout: float\n",
    "            Probability of dropping out a given landmark\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # The base model\n",
    "        self.num_landmarks = num_landmarks\n",
    "        self.conv1 = init_model.conv1\n",
    "        self.bn1 = init_model.bn1\n",
    "        self.relu = init_model.relu\n",
    "        self.maxpool = init_model.maxpool\n",
    "        self.layer1 = init_model.layer1\n",
    "        self.layer2 = init_model.layer2\n",
    "        self.layer3 = init_model.layer3\n",
    "        self.layer4 = init_model.layer4\n",
    "        self.finalpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # New part of the model\n",
    "        self.softmax: Softmax2d = torch.nn.Softmax2d()\n",
    "        self.batchnorm = BatchNorm2d(11)\n",
    "        # self.fc_landmarks = torch.nn.Conv2d(1024 + 2048, num_landmarks + 1, 1, bias=False)\n",
    "        self.landmarks = torch.nn.Parameter(torch.randn(num_landmarks + 1, 1024 + 2048))\n",
    "\n",
    "        self.fc_class_landmarks = torch.nn.Linear(1024 + 2048, num_classes, bias=False)\n",
    "        self.modulation = torch.nn.Parameter(torch.ones((1,1024 + 2048,num_landmarks + 1)))\n",
    "        self.dropout = torch.nn.Dropout(landmark_dropout)\n",
    "        self.dropout_full_landmarks = torch.nn.Dropout1d(landmark_dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            Input image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        all_features: torch.Tensor\n",
    "            Features per landmark\n",
    "        maps: torch.Tensor\n",
    "            Attention maps per landmark\n",
    "        scores: torch.Tensor\n",
    "            Classification scores per landmark\n",
    "        \"\"\"\n",
    "        # Pretrained ResNet part of the model\n",
    "        x = self.conv1(x) # shape: [b, 64, h1, w1], e.g. h1=w1=112\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x) # shape: [b, 64, h2, w2], e.g. h2=w2=56\n",
    "        x = self.layer1(x) # shape: [b, 256, h2, w2], e.g. h2=w2=56\n",
    "        x = self.layer2(x) # shape: [b, 512, h3, w3], e.g. h2=w2=28\n",
    "        l3 = self.layer3(x) # shape: [b, 1024, h3, w3], e.g. h2=w2=28\n",
    "        x = self.layer4(l3) # shape: [b, 2048, h4, w4], e.g. h2=w2=7\n",
    "        # x = torch.nn.functional.upsample_bilinear(x, size=(l3.shape[-2], l3.shape[-1]))\n",
    "        x = torch.nn.functional.interpolate(x, size=(l3.shape[-2], l3.shape[-1]), mode='bilinear') # shape: [b, 2048, h, w], e.g. h=w=14\n",
    "        x = torch.cat((x, l3), dim=1) # shape: [b, 2048 + 1024, h, w], e.g. h=w=14\n",
    "\n",
    "        # Compute per landmark attention maps\n",
    "        b, c, h, w = x.shape\n",
    "        x_flat = x.reshape(b, c, h*w).permute(0, 2, 1) # shape: [b, h*w, 2048 + 1024]\n",
    "        maps = torch.cdist(x_flat, self.landmarks, p=2) # shape: [b, h*w, nlandmarks]\n",
    "        maps = maps.permute(0, 2, 1).reshape(b, -1, h, w) # shape: [b, nlandmarks, h, w]\n",
    "        # Softmax so that the attention maps for each pixel add up to 1\n",
    "        maps = self.softmax(-maps)\n",
    "\n",
    "        # Use maps to get weighted average features per landmark\n",
    "        feature_tensor = x\n",
    "        all_features = ((maps).unsqueeze(1) * feature_tensor.unsqueeze(2)).mean(-1).mean(-1)\n",
    "\n",
    "        # Classification based on the landmarks\n",
    "        all_features_modulated = all_features * self.modulation\n",
    "        all_features_modulated = self.dropout_full_landmarks(all_features_modulated.permute(0,2,1)).permute(0,2,1)\n",
    "        scores = self.fc_class_landmarks(all_features_modulated.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        return all_features, maps, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "IndividualLandmarkNetModified            55,296\n",
       "├─Conv2d: 1-1                            9,408\n",
       "├─BatchNorm2d: 1-2                       128\n",
       "├─ReLU: 1-3                              --\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Sequential: 1-5                        --\n",
       "│    └─Bottleneck: 2-1                   --\n",
       "│    │    └─Conv2d: 3-1                  4,096\n",
       "│    │    └─BatchNorm2d: 3-2             128\n",
       "│    │    └─Conv2d: 3-3                  36,864\n",
       "│    │    └─BatchNorm2d: 3-4             128\n",
       "│    │    └─Conv2d: 3-5                  16,384\n",
       "│    │    └─BatchNorm2d: 3-6             512\n",
       "│    │    └─ReLU: 3-7                    --\n",
       "│    │    └─Sequential: 3-8              16,896\n",
       "│    └─Bottleneck: 2-2                   --\n",
       "│    │    └─Conv2d: 3-9                  16,384\n",
       "│    │    └─BatchNorm2d: 3-10            128\n",
       "│    │    └─Conv2d: 3-11                 36,864\n",
       "│    │    └─BatchNorm2d: 3-12            128\n",
       "│    │    └─Conv2d: 3-13                 16,384\n",
       "│    │    └─BatchNorm2d: 3-14            512\n",
       "│    │    └─ReLU: 3-15                   --\n",
       "│    └─Bottleneck: 2-3                   --\n",
       "│    │    └─Conv2d: 3-16                 16,384\n",
       "│    │    └─BatchNorm2d: 3-17            128\n",
       "│    │    └─Conv2d: 3-18                 36,864\n",
       "│    │    └─BatchNorm2d: 3-19            128\n",
       "│    │    └─Conv2d: 3-20                 16,384\n",
       "│    │    └─BatchNorm2d: 3-21            512\n",
       "│    │    └─ReLU: 3-22                   --\n",
       "├─Sequential: 1-6                        --\n",
       "│    └─Bottleneck: 2-4                   --\n",
       "│    │    └─Conv2d: 3-23                 32,768\n",
       "│    │    └─BatchNorm2d: 3-24            256\n",
       "│    │    └─Conv2d: 3-25                 147,456\n",
       "│    │    └─BatchNorm2d: 3-26            256\n",
       "│    │    └─Conv2d: 3-27                 65,536\n",
       "│    │    └─BatchNorm2d: 3-28            1,024\n",
       "│    │    └─ReLU: 3-29                   --\n",
       "│    │    └─Sequential: 3-30             132,096\n",
       "│    └─Bottleneck: 2-5                   --\n",
       "│    │    └─Conv2d: 3-31                 65,536\n",
       "│    │    └─BatchNorm2d: 3-32            256\n",
       "│    │    └─Conv2d: 3-33                 147,456\n",
       "│    │    └─BatchNorm2d: 3-34            256\n",
       "│    │    └─Conv2d: 3-35                 65,536\n",
       "│    │    └─BatchNorm2d: 3-36            1,024\n",
       "│    │    └─ReLU: 3-37                   --\n",
       "│    └─Bottleneck: 2-6                   --\n",
       "│    │    └─Conv2d: 3-38                 65,536\n",
       "│    │    └─BatchNorm2d: 3-39            256\n",
       "│    │    └─Conv2d: 3-40                 147,456\n",
       "│    │    └─BatchNorm2d: 3-41            256\n",
       "│    │    └─Conv2d: 3-42                 65,536\n",
       "│    │    └─BatchNorm2d: 3-43            1,024\n",
       "│    │    └─ReLU: 3-44                   --\n",
       "│    └─Bottleneck: 2-7                   --\n",
       "│    │    └─Conv2d: 3-45                 65,536\n",
       "│    │    └─BatchNorm2d: 3-46            256\n",
       "│    │    └─Conv2d: 3-47                 147,456\n",
       "│    │    └─BatchNorm2d: 3-48            256\n",
       "│    │    └─Conv2d: 3-49                 65,536\n",
       "│    │    └─BatchNorm2d: 3-50            1,024\n",
       "│    │    └─ReLU: 3-51                   --\n",
       "├─Sequential: 1-7                        --\n",
       "│    └─Bottleneck: 2-8                   --\n",
       "│    │    └─Conv2d: 3-52                 131,072\n",
       "│    │    └─BatchNorm2d: 3-53            512\n",
       "│    │    └─Conv2d: 3-54                 589,824\n",
       "│    │    └─BatchNorm2d: 3-55            512\n",
       "│    │    └─Conv2d: 3-56                 262,144\n",
       "│    │    └─BatchNorm2d: 3-57            2,048\n",
       "│    │    └─ReLU: 3-58                   --\n",
       "│    │    └─Sequential: 3-59             526,336\n",
       "│    └─Bottleneck: 2-9                   --\n",
       "│    │    └─Conv2d: 3-60                 262,144\n",
       "│    │    └─BatchNorm2d: 3-61            512\n",
       "│    │    └─Conv2d: 3-62                 589,824\n",
       "│    │    └─BatchNorm2d: 3-63            512\n",
       "│    │    └─Conv2d: 3-64                 262,144\n",
       "│    │    └─BatchNorm2d: 3-65            2,048\n",
       "│    │    └─ReLU: 3-66                   --\n",
       "│    └─Bottleneck: 2-10                  --\n",
       "│    │    └─Conv2d: 3-67                 262,144\n",
       "│    │    └─BatchNorm2d: 3-68            512\n",
       "│    │    └─Conv2d: 3-69                 589,824\n",
       "│    │    └─BatchNorm2d: 3-70            512\n",
       "│    │    └─Conv2d: 3-71                 262,144\n",
       "│    │    └─BatchNorm2d: 3-72            2,048\n",
       "│    │    └─ReLU: 3-73                   --\n",
       "│    └─Bottleneck: 2-11                  --\n",
       "│    │    └─Conv2d: 3-74                 262,144\n",
       "│    │    └─BatchNorm2d: 3-75            512\n",
       "│    │    └─Conv2d: 3-76                 589,824\n",
       "│    │    └─BatchNorm2d: 3-77            512\n",
       "│    │    └─Conv2d: 3-78                 262,144\n",
       "│    │    └─BatchNorm2d: 3-79            2,048\n",
       "│    │    └─ReLU: 3-80                   --\n",
       "│    └─Bottleneck: 2-12                  --\n",
       "│    │    └─Conv2d: 3-81                 262,144\n",
       "│    │    └─BatchNorm2d: 3-82            512\n",
       "│    │    └─Conv2d: 3-83                 589,824\n",
       "│    │    └─BatchNorm2d: 3-84            512\n",
       "│    │    └─Conv2d: 3-85                 262,144\n",
       "│    │    └─BatchNorm2d: 3-86            2,048\n",
       "│    │    └─ReLU: 3-87                   --\n",
       "│    └─Bottleneck: 2-13                  --\n",
       "│    │    └─Conv2d: 3-88                 262,144\n",
       "│    │    └─BatchNorm2d: 3-89            512\n",
       "│    │    └─Conv2d: 3-90                 589,824\n",
       "│    │    └─BatchNorm2d: 3-91            512\n",
       "│    │    └─Conv2d: 3-92                 262,144\n",
       "│    │    └─BatchNorm2d: 3-93            2,048\n",
       "│    │    └─ReLU: 3-94                   --\n",
       "├─Sequential: 1-8                        --\n",
       "│    └─Bottleneck: 2-14                  --\n",
       "│    │    └─Conv2d: 3-95                 524,288\n",
       "│    │    └─BatchNorm2d: 3-96            1,024\n",
       "│    │    └─Conv2d: 3-97                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-98            1,024\n",
       "│    │    └─Conv2d: 3-99                 1,048,576\n",
       "│    │    └─BatchNorm2d: 3-100           4,096\n",
       "│    │    └─ReLU: 3-101                  --\n",
       "│    │    └─Sequential: 3-102            2,101,248\n",
       "│    └─Bottleneck: 2-15                  --\n",
       "│    │    └─Conv2d: 3-103                1,048,576\n",
       "│    │    └─BatchNorm2d: 3-104           1,024\n",
       "│    │    └─Conv2d: 3-105                2,359,296\n",
       "│    │    └─BatchNorm2d: 3-106           1,024\n",
       "│    │    └─Conv2d: 3-107                1,048,576\n",
       "│    │    └─BatchNorm2d: 3-108           4,096\n",
       "│    │    └─ReLU: 3-109                  --\n",
       "│    └─Bottleneck: 2-16                  --\n",
       "│    │    └─Conv2d: 3-110                1,048,576\n",
       "│    │    └─BatchNorm2d: 3-111           1,024\n",
       "│    │    └─Conv2d: 3-112                2,359,296\n",
       "│    │    └─BatchNorm2d: 3-113           1,024\n",
       "│    │    └─Conv2d: 3-114                1,048,576\n",
       "│    │    └─BatchNorm2d: 3-115           4,096\n",
       "│    │    └─ReLU: 3-116                  --\n",
       "├─AdaptiveAvgPool2d: 1-9                 --\n",
       "├─Softmax2d: 1-10                        --\n",
       "├─BatchNorm2d: 1-11                      22\n",
       "├─Linear: 1-12                           6,144,000\n",
       "├─Dropout: 1-13                          --\n",
       "├─Dropout1d: 1-14                        --\n",
       "=================================================================\n",
       "Total params: 29,707,350\n",
       "Trainable params: 29,707,350\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = resnet50()\n",
    "landmark_net = IndividualLandmarkNetModified(init_model=resnet)\n",
    "x = torch.randn(3, 224, 224)\n",
    "summary(landmark_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maps shape: torch.Size([1, 9, 14, 14])\n",
      "all_features shape: torch.Size([1, 3072, 9])\n"
     ]
    }
   ],
   "source": [
    "feats, maps, scores = landmark_net(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
