{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torch.nn import BatchNorm2d, Softmax2d\n",
    "from torchvision.models.resnet import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = torch.randn(10, 50), torch.randn(20, 50)\n",
    "torch.nn.functional.softmax(torch.cdist(a, b, p=2), dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3072, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Conv2d(1024 + 2048, 10, 1, bias=False).weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualLandmarkNet(torch.nn.Module):\n",
    "    def __init__(self, init_model: ResNet, num_landmarks: int = 8,\n",
    "                 num_classes: int = 2000, landmark_dropout: float = 0.3) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        init_model: ResNet\n",
    "            The pretrained ResNet model\n",
    "        num_landmarks: int\n",
    "            Number of landmarks to detect\n",
    "        num_classes: int\n",
    "            Number of classes for the classification\n",
    "        landmark_dropout: float\n",
    "            Probability of dropping out a given landmark\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # The base model\n",
    "        self.num_landmarks = num_landmarks\n",
    "        self.conv1 = init_model.conv1\n",
    "        self.bn1 = init_model.bn1\n",
    "        self.relu = init_model.relu\n",
    "        self.maxpool = init_model.maxpool\n",
    "        self.layer1 = init_model.layer1\n",
    "        self.layer2 = init_model.layer2\n",
    "        self.layer3 = init_model.layer3\n",
    "        self.layer4 = init_model.layer4\n",
    "        self.finalpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # New part of the model\n",
    "        self.softmax: Softmax2d = torch.nn.Softmax2d()\n",
    "        self.batchnorm = BatchNorm2d(11)\n",
    "        self.fc_landmarks = torch.nn.Conv2d(1024 + 2048, num_landmarks + 1, 1, bias=False)\n",
    "        self.fc_class_landmarks = torch.nn.Linear(1024 + 2048, num_classes, bias=False)\n",
    "        self.modulation = torch.nn.Parameter(torch.ones((1,1024 + 2048,num_landmarks + 1)))\n",
    "        self.dropout = torch.nn.Dropout(landmark_dropout)\n",
    "        self.dropout_full_landmarks = torch.nn.Dropout1d(landmark_dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            Input image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        all_features: torch.Tensor\n",
    "            Features per landmark\n",
    "        maps: torch.Tensor\n",
    "            Attention maps per landmark\n",
    "        scores: torch.Tensor\n",
    "            Classification scores per landmark\n",
    "        \"\"\"\n",
    "        # Pretrained ResNet part of the model\n",
    "        x = self.conv1(x) # shape: [b, 64, h1, w1], e.g. h1=w1=112\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x) # shape: [b, 64, h2, w2], e.g. h2=w2=56\n",
    "        x = self.layer1(x) # shape: [b, 256, h2, w2], e.g. h2=w2=56\n",
    "        x = self.layer2(x) # shape: [b, 512, h3, w3], e.g. h2=w2=28\n",
    "        l3 = self.layer3(x) # shape: [b, 1024, h3, w3], e.g. h2=w2=28\n",
    "        x = self.layer4(l3) # shape: [b, 2048, h4, w4], e.g. h2=w2=7\n",
    "        # x = torch.nn.functional.upsample_bilinear(x, size=(l3.shape[-2], l3.shape[-1]))\n",
    "        x = torch.nn.functional.interpolate(x, size=(l3.shape[-2], l3.shape[-1]), mode='bilinear') # shape: [b, 2048, h, w], e.g. h=w=14\n",
    "        x = torch.cat((x, l3), dim=1) # shape: [b, 2048 + 1024, h, w], e.g. h=w=14\n",
    "\n",
    "        # Compute per landmark attention maps\n",
    "        # (b - a)^2 = b^2 - 2ab + a^2, b = feature maps resnet, a = convolution kernel\n",
    "        batch_size = x.shape[0]\n",
    "        ab = self.fc_landmarks(x) # shape: [b, nlandmark + 1, h, w]\n",
    "        print('ab shape:', ab.shape)\n",
    "        b_sq = x.pow(2).sum(1, keepdim=True) # shape: [b, 1, h, w]\n",
    "        print('b_sq shape:', b_sq.shape)\n",
    "        b_sq = b_sq.expand(-1, self.num_landmarks + 1, -1, -1) # shape: [b, nlandmark + 1, h, w]\n",
    "        print('b_sq shape:', b_sq.shape)\n",
    "        print('fc_landmarks.weight shape:', self.fc_landmarks.weight.shape)\n",
    "        a_sq = self.fc_landmarks.weight.pow(2).sum(1).unsqueeze(1).expand(-1, batch_size, x.shape[-2], x.shape[-1])\n",
    "        print('a_sq shape:', a_sq.shape)\n",
    "        a_sq = a_sq.permute(1, 0, 2, 3)\n",
    "        maps = b_sq - 2 * ab + a_sq\n",
    "        maps = -maps\n",
    "\n",
    "        # Softmax so that the attention maps for each pixel add up to 1\n",
    "        print('maps shape:', maps.shape)\n",
    "        maps = self.softmax(maps)\n",
    "\n",
    "        # Use maps to get weighted average features per landmark\n",
    "        feature_tensor = x\n",
    "        all_features = ((maps).unsqueeze(1) * feature_tensor.unsqueeze(2)).mean(-1).mean(-1)\n",
    "        print('all_features shape:', all_features.shape)\n",
    "\n",
    "        # Classification based on the landmarks\n",
    "        all_features_modulated = all_features * self.modulation\n",
    "        all_features_modulated = self.dropout_full_landmarks(all_features_modulated.permute(0,2,1)).permute(0,2,1)\n",
    "        scores = self.fc_class_landmarks(all_features_modulated.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        return all_features, maps, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet50()\n",
    "landmark_net = IndividualLandmarkNet(init_model=resnet)\n",
    "x = torch.randn(3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab shape: torch.Size([1, 9, 14, 14])\n",
      "b_sq shape: torch.Size([1, 1, 14, 14])\n",
      "b_sq shape: torch.Size([1, 9, 14, 14])\n",
      "fc_landmarks.weight shape: torch.Size([9, 3072, 1, 1])\n",
      "a_sq shape: torch.Size([9, 1, 14, 14])\n",
      "maps shape: torch.Size([1, 9, 14, 14])\n",
      "all_features shape: torch.Size([1, 3072, 9])\n"
     ]
    }
   ],
   "source": [
    "feats, maps, scores = landmark_net(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualLandmarkNetModified(torch.nn.Module):\n",
    "    def __init__(self, init_model: ResNet, num_landmarks: int = 8,\n",
    "                 num_classes: int = 2000, landmark_dropout: float = 0.3) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        init_model: ResNet\n",
    "            The pretrained ResNet model\n",
    "        num_landmarks: int\n",
    "            Number of landmarks to detect\n",
    "        num_classes: int\n",
    "            Number of classes for the classification\n",
    "        landmark_dropout: float\n",
    "            Probability of dropping out a given landmark\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # The base model\n",
    "        self.num_landmarks = num_landmarks\n",
    "        self.conv1 = init_model.conv1\n",
    "        self.bn1 = init_model.bn1\n",
    "        self.relu = init_model.relu\n",
    "        self.maxpool = init_model.maxpool\n",
    "        self.layer1 = init_model.layer1\n",
    "        self.layer2 = init_model.layer2\n",
    "        self.layer3 = init_model.layer3\n",
    "        self.layer4 = init_model.layer4\n",
    "        self.finalpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # New part of the model\n",
    "        self.softmax: Softmax2d = torch.nn.Softmax2d()\n",
    "        self.batchnorm = BatchNorm2d(11)\n",
    "        # self.fc_landmarks = torch.nn.Conv2d(1024 + 2048, num_landmarks + 1, 1, bias=False)\n",
    "        self.landmarks = torch.nn.Parameter(torch.randn(num_landmarks + 1, 1024 + 2048))\n",
    "\n",
    "        self.fc_class_landmarks = torch.nn.Linear(1024 + 2048, num_classes, bias=False)\n",
    "        self.modulation = torch.nn.Parameter(torch.ones((1,1024 + 2048,num_landmarks + 1)))\n",
    "        self.dropout = torch.nn.Dropout(landmark_dropout)\n",
    "        self.dropout_full_landmarks = torch.nn.Dropout1d(landmark_dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            Input image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        all_features: torch.Tensor\n",
    "            Features per landmark\n",
    "        maps: torch.Tensor\n",
    "            Attention maps per landmark\n",
    "        scores: torch.Tensor\n",
    "            Classification scores per landmark\n",
    "        \"\"\"\n",
    "        # Pretrained ResNet part of the model\n",
    "        x = self.conv1(x) # shape: [b, 64, h1, w1], e.g. h1=w1=112\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x) # shape: [b, 64, h2, w2], e.g. h2=w2=56\n",
    "        x = self.layer1(x) # shape: [b, 256, h2, w2], e.g. h2=w2=56\n",
    "        x = self.layer2(x) # shape: [b, 512, h3, w3], e.g. h2=w2=28\n",
    "        l3 = self.layer3(x) # shape: [b, 1024, h3, w3], e.g. h2=w2=28\n",
    "        x = self.layer4(l3) # shape: [b, 2048, h4, w4], e.g. h2=w2=7\n",
    "        # x = torch.nn.functional.upsample_bilinear(x, size=(l3.shape[-2], l3.shape[-1]))\n",
    "        x = torch.nn.functional.interpolate(x, size=(l3.shape[-2], l3.shape[-1]), mode='bilinear') # shape: [b, 2048, h, w], e.g. h=w=14\n",
    "        x = torch.cat((x, l3), dim=1) # shape: [b, 2048 + 1024, h, w], e.g. h=w=14\n",
    "\n",
    "        # Compute per landmark attention maps\n",
    "        # (b - a)^2 = b^2 - 2ab + a^2, b = feature maps resnet, a = convolution kernel\n",
    "        b, c, h, w = x.shape\n",
    "        x_flat = x.reshape(b, c, h*w).permute(0, 2, 1) # shape: [b, h*w, 2048 + 1024]\n",
    "        maps = torch.cdist(x_flat, self.landmarks, p=2) # shape: [b, h*w, nlandmarks]\n",
    "        maps = maps.permute(0, 2, 1).reshape(b, -1, h, w) # shape: [b, nlandmarks, h, w]\n",
    "        # Softmax so that the attention maps for each pixel add up to 1\n",
    "        maps = self.softmax(-maps)\n",
    "\n",
    "        # Use maps to get weighted average features per landmark\n",
    "        feature_tensor = x\n",
    "        all_features = ((maps).unsqueeze(1) * feature_tensor.unsqueeze(2)).mean(-1).mean(-1)\n",
    "\n",
    "        # Classification based on the landmarks\n",
    "        all_features_modulated = all_features * self.modulation\n",
    "        all_features_modulated = self.dropout_full_landmarks(all_features_modulated.permute(0,2,1)).permute(0,2,1)\n",
    "        scores = self.fc_class_landmarks(all_features_modulated.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        return all_features, maps, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet50()\n",
    "landmark_net = IndividualLandmarkNetModified(init_model=resnet)\n",
    "x = torch.randn(3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maps shape: torch.Size([1, 9, 14, 14])\n",
      "all_features shape: torch.Size([1, 3072, 9])\n"
     ]
    }
   ],
   "source": [
    "feats, maps, scores = landmark_net(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
